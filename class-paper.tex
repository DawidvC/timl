%-----------------------------------------------------------------------------
%
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------


\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath,amsfonts,amscd,amssymb,proof,MnSymbol}
\usepackage{mathpartir}
\usepackage{turnstile}% http://ctan.org/pkg/turnstile
\usepackage{adjustbox}% http://ctan.org/pkg/adjustbox
\usepackage{color}

\renewcommand{\makehor}[4]
  {\ifthenelse{\equal{#1}{n}}{\hspace{#3}}{}
   \ifthenelse{\equal{#1}{s}}{\rule[-0.5#2]{#3}{#2}}{}
   \ifthenelse{\equal{#1}{d}}{\setlength{\lengthvar}{#2}
     \addtolength{\lengthvar}{0.5#4}
     \rule[-\lengthvar]{#3}{#2}
     \hspace{-#3}
     \rule[0.5#4]{#3}{#2}}{}
   \ifthenelse{\equal{#1}{t}}{\setlength{\lengthvar}{1.5#2}
     \addtolength{\lengthvar}{#4}
     \rule[-\lengthvar]{#3}{#2}
     \hspace{-#3}
     \rule[-0.5#2]{#3}{#2}
     \hspace{-#3}
     \setlength{\lengthvar}{0.5#2}
     \addtolength{\lengthvar}{#4}
     \rule[\lengthvar]{#3}{#2}}{}
   \ifthenelse{\equal{#1}{w}}{% New wavy $\sim$ definition
     \setbox0=\hbox{$\sim$}%
     \raisebox{-.6ex}{\hspace*{-.05ex}\adjustbox{width=#3,height=\height}{\clipbox{0.75 0 0 0}{\usebox0}}}}{}
  }

\newcommand{\thide}[1]{\left \langle #1 \right \rangle}
\newcommand{\typing}[4]{\turnstile{s}{s}{#4}{#3}{n}#1:#2}
\newcommand{\kinding}[2]{\turnstile{s}{s}{}{}{n}#1:#2}
\newcommand{\teq}[2]{#1\equiv#2}
\newcommand{\arrow}[4]{#1\xrightarrow[#3]{#2}#4}
\newcommand{\symlet}{\mathsf{let\;}}
\newcommand{\symin}{\mathsf{\;in\;}}
\newcommand{\symletrec}{\mathsf{letrec\;}}
\newcommand{\symand}{\mathsf{\;and\;}}
\newcommand{\symmatch}{\mathsf{match}}
\newcommand{\FV}{\mathsf{FV}}
\newcommand{\symwith}{\mathsf{\;with\;}}
\newcommand{\syminl}{\mathsf{inl}}
\newcommand{\syminr}{\mathsf{inr}}
\newcommand{\symmax}{\mathsf{max}}
\newcommand{\symSinl}{\mathsf{Sinl\;}}
\newcommand{\symSinr}{\mathsf{Sinr\;}}
\newcommand{\symfold}{\mathsf{fold\;}}
\newcommand{\symSfold}{\mathsf{Sfold\;}}
\newcommand{\symunfold}{\mathsf{unfold\;}}
\newcommand{\symSunfold}{\mathsf{Sunfold\;}}
\newcommand{\symhide}{\mathsf{hide\;}}
\newcommand{\symShide}{\mathsf{Shide\;}}
\newcommand{\symunhide}{\mathsf{unhide\;}}
\newcommand{\symSunhide}{\mathsf{Sunhide\;}}
\newcommand{\leO}{\preceq}
\newcommand{\sympair}{\mathsf{pair}}
\newcommand{\symtt}{\mathsf{tt}}
\newcommand{\symunit}{\mathsf{unit}}
\newcommand{\symlist}{\mathsf{list}}
\newcommand{\symnil}{\mathsf{nil}}
\newcommand{\symcons}{\mathsf{cons}}
\newcommand{\symfix}{\mathsf{fix}}
\newcommand{\symbool}{\mathsf{bool}}
\newcommand{\symtrue}{\mathsf{true}}
\newcommand{\symfalse}{\mathsf{false}}
\newcommand{\symmerge}{\mathsf{merge}}

%% \newcommand{\intro}[2]{#2^#1}
\newcommand{\intro}[2]{(#1 : #2)}
%% \newcommand{\intro}[2]{(#2 \mathsf{\;size\;} #1)}
%% \newcommand{\intro}[2]{\{#2 \mathsf{\;|\;} #1\}}

\newcommand{\symsum}{\mathsf{sum}}
\newcommand{\symfst}{\mathsf{fst}}
\newcommand{\symsnd}{\mathsf{snd}}
\newcommand{\symif}{\mathsf{if\;}}
\newcommand{\symthen}{\mathsf{\;then\;}}
\newcommand{\symelse}{\mathsf{\;else\;}}
\newcommand{\symSbool}{\mathsf{Sbool}}
\newcommand{\symuf}{\mathsf{uf}}
\newcommand{\symuh}{\mathsf{uh}}
\newcommand{\syml}{\mathsf{l}}
\newcommand{\symr}{\mathsf{r}}
\newcommand{\symf}{\mathsf{f}}
\newcommand{\syms}{\mathsf{s}}
\newcommand{\symmsort}{\mathsf{msort}}
\newcommand{\symSstat}{\mathsf{Sstat}}
\newcommand{\symsplit}{\mathsf{split}}
\newcommand{\symprod}{\mathsf{prod}}
\newcommand{\symStt}{\mathsf{Stt}}
\newcommand{\symSpair}{\mathsf{Spair}}
\newcommand{\symSlr}{\mathsf{Slr}}
\newcommand{\defeq}{\triangleq}
\newcommand{\symwork}{\mathsf{w}}
\newcommand{\symspan}{\mathsf{s}}

\newcommand{\logo}{\lambda^{\forall,\omega,\mu}_\mathrm{c}}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{CONF 'yy}{Month d--d, 20yy, City, ST, Country} 
\copyrightyear{20yy} 
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm} 
\doi{nnnnnnn.nnnnnnn}

% Uncomment one of the following two, if you are not going for the 
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish, 
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers, 
                                  % short abstracts)

%% \titlebanner{banner above paper title}        % These are ignored unless
\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{$\logo$ : Complexity Recursive Types}
%% \subtitle{Subtitle Text, if any}

\authorinfo{Peng Wang}
           {MIT CSAIL}
           {wangpeng@csail.mit.edu}

\maketitle

\begin{abstract}
Efficiency of functional programs is important.
\end{abstract}

%\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore, 
% you may leave them out
%% \terms
%% term1, term2

\keywords
type system; complexity; recursive types

\section{Introduction}

One major obstacle of the adaptation of functional programming is the lack of a clear intuition of functional program's time complexity. A C programmer can easily read off the big-O complexity of a for-loop, but even experienced functional programmers are sometimes muddled about the time complexity of a piece of functional code. The confusion comes from the lack of knowledge of the compiler's inner-working, as stated by the scoff ``you can hide an elephant under a beta reduction''. Two examples of the mythical objects that compilers manage internally are closures and algebraic data values. When one does not know how closures are created, passed, and used, he or she will rightfully wonder the time cost of creating a lambda abstraction, passing a function, and applying a function (beta reduction). For values of algebraic data types such as list, the immutability of these values (one can only construct new values, not in-place modify them) often gives a C programmer the wrong impression that such values are copied and passed-by-value all the time and passing a list will take O(n) time to do the copying. The reality could not be further from this false impression, since immutability means almost everything can be safely implemented by pointers and references.

But requiring every programmer to fully understand to inner-working of functional-language compilers is infeasible and unreasonable. One should be able to reason about properties of her programs in the language in which she actually writes, not in the target language of the compiler. It is the compiler's responsibility to preserve all properties of interest from the source program to the target program. So to demythify the complexity of function programming, two pieces of work need to be done: (1) we need a way to let the programmers easily reason about the complexity of functional programs in the source language level, and (2) we need a compiler that preserves the complexity of the source program downto the target program. This paper deals with the first part, with some assumptions about the second part. 

One usually reason about functional programs using its operational semantics. The closest thing related to time cost in operational semantics is the number of reduction steps (in some counting metric) in small-step operational semantics, with some evaluation strategy. The design choices are (1) which evaluation strategy to use and (2) in which metric to do the counting. For (1), we choose strict call-by-value evaluation strategy against call-by-name strategy, because we think call-by-value fits people's intuition of evaluation order better, and it makes our assumption about the compiler more plausible. Call-by-name evaluation strategy has the drawback that since it can postpone computations and executing them in a sudden burst, a reduction step in the evaluation strategy could take an arbitrary amount of time on a real machine.

For design choice (2), there are work ~\cite{blelloch2013cache} that employ ingenious cost models in which the counting is done, and we do believe that we need well-designed cost models to account for various machine characteristics when we want to have a more precise analysis of the time cost. But for this work, we choose the simplest cost model - the number of reduction steps in a standard strict call-by-value evaluation strategy. The justification for this choice is that (a) our top-level theorem will give any well-typed program a big-O bound on the number of reduction steps, which allows for a constant factor to be the room of imprecision, and (b) we make the assumption that {\bf any reduction step in a standard strict call-by-value evaluation strategy can be implemented by the compiler as a constant-time computation (excluding garbage collection)}. When we later make clear our definition of ``constant'' and ``non-constant'', we will come back to this assumption and try to persuade the reader that this is a reasonable assumption. Combining (a) and (b), we will have a end-to-end theorem of the big-O bound on the actual running time (defined in a well-accepted machine model such as the Random Access Machine (RAM)), independent of our choice of functional cost model, which can be treated as a intermediate proof step.

Using such a cost model, programmers can do the counting in their heads and reason about their programs' complexity informally. However, we want to allow programmers to formally express their complexity constraints in a type system, which can formally guarantee the complexity via type-checking. Type systems are for preventing bugs, and we think that calling a function of a wrong complexity order, such as calling an O(n) function when an O(1) one is intended, is really a bug, not a ``performance issue''. Complexity, or at least complexity order, should be a constituent of functional correctness.

We designed such a type system for the calculus $\lambda^{\forall,\omega\,\mu}$ (that is, lambda calculus extended with impredicative (first-class) universal polymorphism, type-level operator, and recursive types). Our main contribution is {\bf the first complexity type system with recursive types}. We believe this is an important milestone because the combing power of $\lambda^\forall$, $\lambda^\omega$, and $\lambda^\mu$ gives the ability to define generic algebraic data types such as lists and trees, which is the minimal requirement for a functional language to become practically ``useful''.

We imagine two groups of potential users for such a language and type system. The first group is everyone programmers, for whom this type system can be incorporated into the ML language and provide additional benefits besides the already very useful ML type system. To be user-friendly, we must have a type checker (which means the type system needs to be proved decidable) and do reasonable degree of type inference. We will discuss this in Section \ref{section-example} and leave it as future work.

The second group of users are computer theorists conducting complexity proofs of algorithms. As ~\cite{harper2014proposal} points out, there is an unfornately crevice between ``combinatorial'' theoriests and programming language theoriests. Members of the former still believe that the only mathematically rigid way to do complexity analysis is on the assembly level - on the Turning Machine model or Random Access Machine model; while the latter community has decades of achievements raising the abstraction level and building large systems \emph{compositionally} out of smaller components. The combinatorial theorists actually often give up rigidity by using some ``pseudo-code'' in the papers and assume that the reader can straight-forwardly ``compile'' the pseudo-code into rigid RAM code in his or her head. We hope that our language can serve as the start point when computer theoriests can express their complexity proof in a rigid whilst high-level formal language, enjoying the benefits of modern functional languages such as compositionality and abstraction. Our language is only a start point because it still lacks such important features as mutable references (and mutable arrays), which is essential for implementing matrix-based numeric algorithms; and such advanced complexity analysis as probablistic and amortized analysis, which have become mainstream for modern complexity analysis. We also lack parallelism, though in our design we intentionlly have the generality (we have the notion of ``work'' and ``span'') to make later extension to parallelism easier.

Section \ref{section-example} will give an illustrating example, the merge-sort, to show what the type system can express. It will also give the top-level type soundness theorem. Section \ref{section-lang} defines the language and the typing rules. Section \ref{section-proof} gives the proof of the type soundness, using Logical Step-indexed Logical Relation ~\cite{dreyer2009logical}. Section \ref{section-related} discusses related work. Section \ref{section-discussion} discusses this work's strength and limitations, future work and conclusion.

\section{\label{section-example}Example: merge-sort}

\begin{align*}
\symmsort &\defeq \lambda A. \lambda cmp.\;\symfix\;f(xs). \\
& \hspace{.1in} \symmatch\;xs\symwith \\
& \hspace{.2in} |\; \symnil\Rightarrow xs \\
& \hspace{.2in} |\; \_::xs' \Rightarrow \symmatch\;xs'\symwith \\
& \hspace{.3in} |\; \symnil\Rightarrow xs \\
& \hspace{.3in} |\; \_ \Rightarrow \symmatch\; \symsplit\;xs \symwith \\
& \hspace{.4in} |\; (ys, zs) \Rightarrow \symmerge\;cmp\;(f\;ys)\;(f\;zs) \\
\\
& \hspace{-0.2in} : \forall A.\arrow{(\arrow{A}{0}{1}{\arrow{A}{1}{1}{\symbool}})}{0}{1}{\arrow{\intro{s}{\symlist\;A}}{s*\log(s)}{<s>}{\symlist\;A}} \\
\mathsf{where} & \\
\end{align*}

\section{\label{section-lang}Language and Type System}

\section{\label{section-proof}Type Soundness Proof}

\section{\label{section-related}Related Work}

\section{\label{section-discussion}Discussion and Conclusion}

\appendix

%% \acks

%% Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\bibliography{bib.bib}

%% \begin{thebibliography}{}
%% \softraggedright

%% \bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
%% P. Q. Smith, and X. Y. Jones. ...reference text...

%% \end{thebibliography}


\end{document}

%                       Revision History
%                       -------- -------
%  Date         Person  Ver.    Change
%  ----         ------  ----    ------

%  2013.06.29   TU      0.1--4  comments on permission/copyright notices

